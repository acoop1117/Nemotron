run:
  data: PretrainBlendsArtifact-pretrain:latest
  env:
    container: nvcr.io/nvidian/nemo:25.11-nano-v3.rc2
  wandb:
    project: nemotron
    entity: romeyn


recipe:
  per_split_data_args_path: ${art:data,path}/blend.json


train:
  train_iters: 1000
  global_batch_size: 32

# model:
#   pipeline_model_parallel_size: 2

tokenizer:
  tokenizer_type: HuggingFaceTokenizer
  tokenizer_model: nvidia/NVIDIA-Nemotron-Nano-9B-v2

scheduler:
  lr_warmup_iters: 32

logger:
  log_interval: 10

checkpoint:
  save: null
  save_interval: 20
