run:
  env:
    container: anyscale/ray:2.49.2-py311

# Config for RL data preparation with HuggingFace placeholder resolution
#
# Processes nvidia/Nemotron-3-Nano-RL-Training-Blend and resolves
# placeholder entries by fetching from external datasets (DAPO, Skywork).
#
# Placeholder records have an `_hf_placeholder` field containing row indices and
# question templates. The data_prep.py script resolves these by:
# 1. Detecting placeholder records by the presence of `_hf_placeholder` field
# 2. Fetching the actual data from the external HF dataset
# 3. Applying template restoration (DAPO prefix/suffix, Skywork {question} replacement)
#
# For simple copy/passthrough (no placeholder resolution), use data_prep_copy.py instead.
#
# Usage:
#   python data_prep.py
#   python data_prep.py sample=100 force=true
#
# Environment variables:
#   PWD: Current working directory (for path resolution)

# Path to data blend JSON file
blend_path: ${oc.env:PWD}/src/nemotron/recipes/nano3/stage2_rl/config/data_prep/data_blend_raw.json

# Output directory for resolved JSONL data (outputs to job directory for persistence)
output_dir: ${oc.env:PWD}/../output/stage2_rl_resolved

# Target size per shard (e.g., '256MB', '1GB')
shard_size: 256MB

# Limit rows per dataset for quick tests (null = no limit)
sample: null

# Ray actors for parallel processing (null = auto)
num_actors: null

# Force new run, ignoring cache
force: false
